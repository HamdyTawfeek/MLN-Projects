{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gsqkl58ryQD7",
    "outputId": "be17040c-401a-45cf-da4c-6c847e708513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ULR43iYNyr9A",
    "outputId": "f8416604-967e-4fe5-96ee-57a1f59d35b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_XqM8j_yQEC"
   },
   "outputs": [],
   "source": [
    "def set_pandas_options():\n",
    "    import warnings\n",
    "    pd.options.display.max_columns = 128\n",
    "    pd.options.display.max_rows = 128\n",
    "    pd.options.display.float_format = '{:.9f}'.format\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "set_pandas_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gmi-aTvm0frk",
    "outputId": "f5bba0d2-469b-446f-8331-b2ec384ef1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Machine Learning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /content/drive/My Drive/Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5brPMiNcyQEE"
   },
   "source": [
    "## 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1IKlKPvyQEF"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EW2p53yxyQEG",
    "outputId": "1bb4d0ac-1b1b-4124-c01a-e5053786178e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 128)\n",
      "(19765, 127)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "FKw-DOIsI2fa",
    "outputId": "dd36eff1-44bc-4243-b27f-fc52ff1c6039"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Product_Info_1', 'Product_Info_2', 'Product_Info_3',\n",
       "       'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7',\n",
       "       'Ins_Age', 'Ht',\n",
       "       ...\n",
       "       'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42',\n",
       "       'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45',\n",
       "       'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48',\n",
       "       'Response'],\n",
       "      dtype='object', length=128)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2210
    },
    "colab_type": "code",
    "id": "yLZvHsGK28_K",
    "outputId": "5f6115d4-b85b-4f2d-bcef-eec62d9ca302"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "Product_Info_1             0\n",
       "Product_Info_2             0\n",
       "Product_Info_3             0\n",
       "Product_Info_4             0\n",
       "Product_Info_5             0\n",
       "Product_Info_6             0\n",
       "Product_Info_7             0\n",
       "Ins_Age                    0\n",
       "Ht                         0\n",
       "Wt                         0\n",
       "BMI                        0\n",
       "Employment_Info_1         19\n",
       "Employment_Info_2          0\n",
       "Employment_Info_3          0\n",
       "Employment_Info_4       6779\n",
       "Employment_Info_5          0\n",
       "Employment_Info_6      10854\n",
       "InsuredInfo_1              0\n",
       "InsuredInfo_2              0\n",
       "InsuredInfo_3              0\n",
       "InsuredInfo_4              0\n",
       "InsuredInfo_5              0\n",
       "InsuredInfo_6              0\n",
       "InsuredInfo_7              0\n",
       "Insurance_History_1        0\n",
       "Insurance_History_2        0\n",
       "Insurance_History_3        0\n",
       "Insurance_History_4        0\n",
       "Insurance_History_5    25396\n",
       "Insurance_History_7        0\n",
       "Insurance_History_8        0\n",
       "Insurance_History_9        0\n",
       "Family_Hist_1              0\n",
       "Family_Hist_2          28656\n",
       "Family_Hist_3          34241\n",
       "Family_Hist_4          19184\n",
       "Family_Hist_5          41811\n",
       "Medical_History_1       8889\n",
       "Medical_History_2          0\n",
       "Medical_History_3          0\n",
       "Medical_History_4          0\n",
       "Medical_History_5          0\n",
       "Medical_History_6          0\n",
       "Medical_History_7          0\n",
       "Medical_History_8          0\n",
       "Medical_History_9          0\n",
       "Medical_History_10     58824\n",
       "Medical_History_11         0\n",
       "Medical_History_12         0\n",
       "Medical_History_13         0\n",
       "Medical_History_14         0\n",
       "Medical_History_15     44596\n",
       "Medical_History_16         0\n",
       "Medical_History_17         0\n",
       "Medical_History_18         0\n",
       "Medical_History_19         0\n",
       "Medical_History_20         0\n",
       "Medical_History_21         0\n",
       "Medical_History_22         0\n",
       "Medical_History_23         0\n",
       "Medical_History_24     55580\n",
       "Medical_History_25         0\n",
       "Medical_History_26         0\n",
       "Medical_History_27         0\n",
       "Medical_History_28         0\n",
       "Medical_History_29         0\n",
       "Medical_History_30         0\n",
       "Medical_History_31         0\n",
       "Medical_History_32     58274\n",
       "Medical_History_33         0\n",
       "Medical_History_34         0\n",
       "Medical_History_35         0\n",
       "Medical_History_36         0\n",
       "Medical_History_37         0\n",
       "Medical_History_38         0\n",
       "Medical_History_39         0\n",
       "Medical_History_40         0\n",
       "Medical_History_41         0\n",
       "Medical_Keyword_1          0\n",
       "Medical_Keyword_2          0\n",
       "Medical_Keyword_3          0\n",
       "Medical_Keyword_4          0\n",
       "Medical_Keyword_5          0\n",
       "Medical_Keyword_6          0\n",
       "Medical_Keyword_7          0\n",
       "Medical_Keyword_8          0\n",
       "Medical_Keyword_9          0\n",
       "Medical_Keyword_10         0\n",
       "Medical_Keyword_11         0\n",
       "Medical_Keyword_12         0\n",
       "Medical_Keyword_13         0\n",
       "Medical_Keyword_14         0\n",
       "Medical_Keyword_15         0\n",
       "Medical_Keyword_16         0\n",
       "Medical_Keyword_17         0\n",
       "Medical_Keyword_18         0\n",
       "Medical_Keyword_19         0\n",
       "Medical_Keyword_20         0\n",
       "Medical_Keyword_21         0\n",
       "Medical_Keyword_22         0\n",
       "Medical_Keyword_23         0\n",
       "Medical_Keyword_24         0\n",
       "Medical_Keyword_25         0\n",
       "Medical_Keyword_26         0\n",
       "Medical_Keyword_27         0\n",
       "Medical_Keyword_28         0\n",
       "Medical_Keyword_29         0\n",
       "Medical_Keyword_30         0\n",
       "Medical_Keyword_31         0\n",
       "Medical_Keyword_32         0\n",
       "Medical_Keyword_33         0\n",
       "Medical_Keyword_34         0\n",
       "Medical_Keyword_35         0\n",
       "Medical_Keyword_36         0\n",
       "Medical_Keyword_37         0\n",
       "Medical_Keyword_38         0\n",
       "Medical_Keyword_39         0\n",
       "Medical_Keyword_40         0\n",
       "Medical_Keyword_41         0\n",
       "Medical_Keyword_42         0\n",
       "Medical_Keyword_43         0\n",
       "Medical_Keyword_44         0\n",
       "Medical_Keyword_45         0\n",
       "Medical_Keyword_46         0\n",
       "Medical_Keyword_47         0\n",
       "Medical_Keyword_48         0\n",
       "Response                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "spXg7E4VCX58",
    "outputId": "1a73057d-f5cb-4bf7-a4b1-5ee134240f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of nan values in train set : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Employment_Info_1     0.000319968\n",
       "Employment_Info_4     0.114161095\n",
       "Employment_Info_6     0.182785740\n",
       "Insurance_History_5   0.427678887\n",
       "Family_Hist_2         0.482578603\n",
       "Family_Hist_3         0.576632256\n",
       "Family_Hist_4         0.323066301\n",
       "Family_Hist_5         0.704114111\n",
       "Medical_History_1     0.149694347\n",
       "Medical_History_10    0.990619895\n",
       "Medical_History_15    0.751014634\n",
       "Medical_History_24    0.935989626\n",
       "Medical_History_32    0.981357673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('proportion of nan values in train set : ')\n",
    "prop = train.isnull().sum(axis = 0)/len(train)\n",
    "prop[prop != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "63JyseWOsRf7",
    "outputId": "b398fc3a-3634-4621-dd5c-e4a5e902d7fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    19489\n",
       "6    11233\n",
       "7     8027\n",
       "2     6552\n",
       "1     6207\n",
       "5     5432\n",
       "4     1428\n",
       "3     1013\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "l23xLVjC1axV",
    "outputId": "bc959690-097f-40dc-b919-c4f886b161c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAG9CAYAAACI+uCjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# response distribution\n",
    "fig, ax = plt.subplots(1,1,figsize=(13,7))\n",
    "sns.countplot(x='Response',data=train, ax=ax)\n",
    "plt.xlabel('Response',fontsize=13)\n",
    "plt.ylabel('Count',fontsize=13)\n",
    "plt.title('Distribution of the Response variable (final decision associated with an application)',fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xb4ZGenB7Vfj"
   },
   "source": [
    "**Age, Height, Weight, BMI VS Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "QVSYDJFo6AR2",
    "outputId": "9476ebc3-a5b7-4374-acc9-7bb22e87e2bd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAD+CAYAAACOVUaKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['Response', 'Ins_Age', 'Ht', 'Wt', 'BMI']\n",
    "correlations = train[cols].corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,5,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(cols)\n",
    "ax.set_yticklabels(cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWUtxp4c4Wfb"
   },
   "outputs": [],
   "source": [
    "## old graphs\n",
    "# facet = sns.FacetGrid(train, hue=\"Response\",aspect=4, hue_order=[1,2,3,4,5,6,7,8], palette=\"RdBu\")\n",
    "# facet.map(sns.kdeplot,'Ins_Age')\n",
    "# facet.set(xlim=(0, train['Ins_Age'].max()))\n",
    "# facet.add_legend();\n",
    "# plt.xlabel('Age of applicant',fontsize=13)\n",
    "# plt.title('Distribution of responses across normalized ages')\n",
    "\n",
    "# facet = sns.FacetGrid(train, hue=\"Response\",aspect=4, hue_order=[1,2,3,4,5,6,7,8], palette=\"RdBu\")\n",
    "# facet.map(sns.kdeplot,'Ht')\n",
    "# facet.set(xlim=(0.4, train['Ht'].max()))\n",
    "# facet.add_legend()\n",
    "# plt.xlabel('Normalized Height of applicant',fontsize=13)\n",
    "# plt.title('Distribution of responses across normalized Heights')\n",
    "\n",
    "# facet = sns.FacetGrid(train, hue=\"Response\",aspect=4, hue_order=[1,2,3,4,5,6,7,8], palette=\"RdBu\")\n",
    "# facet.map(sns.kdeplot,'Wt')\n",
    "# facet.set(xlim=(0, train['Wt'].max()))\n",
    "# facet.add_legend();\n",
    "# plt.xlabel('Normalized Weight of applicant',fontsize=13)\n",
    "# plt.title('Distribution of responses across normalized weights')\n",
    "\n",
    "# facet = sns.FacetGrid(train, hue=\"Response\",aspect=4, hue_order=[1,2,3,4,5,6,7,8], palette=\"RdBu\")\n",
    "# facet.map(sns.kdeplot,'BMI')\n",
    "# facet.set(xlim=(0, 1.0))\n",
    "# facet.add_legend()\n",
    "# plt.xlabel('Normalized BMI of applicant',fontsize=13)\n",
    "# plt.title('Distribution of responses across normalized BMI')\n",
    "\n",
    "# fig, axes  = plt.subplots(nrows=2, ncols=2,figsize=(15,10))\n",
    "# sns.boxplot(x=\"Response\", y=\"Ins_Age\", data=train, order=[1,2,3,4,5,6,7,8], palette=\"RdBu\",ax=axes[0,0])\n",
    "# sns.boxplot(x=\"Response\", y=\"Ht\", data=train, order=[1,2,3,4,5,6,7,8], palette=\"RdBu\",ax=axes[0,1])\n",
    "# sns.boxplot(x=\"Response\", y=\"Wt\", data=train, order=[1,2,3,4,5,6,7,8], palette=\"RdBu\",ax=axes[1,0])\n",
    "# sns.boxplot(x=\"Response\", y=\"BMI\", data=train, order=[1,2,3,4,5,6,7,8], palette=\"RdBu\",ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGxGkyDhyQEP"
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLSpbkeFrmH0"
   },
   "outputs": [],
   "source": [
    "class StandardScaler_df:\n",
    "    def __init__(self):\n",
    "        self.StandardScaler = StandardScaler()\n",
    "    def fit(self, df):\n",
    "        self.StandardScaler.fit(df)\n",
    "    def transform(self, df):\n",
    "        df = pd.DataFrame(self.StandardScaler.transform(df), columns=df.columns)\n",
    "        return df\n",
    "    def fit_transform(self, df):\n",
    "        df = pd.DataFrame(self.StandardScaler.fit_transform(df), columns=df.columns)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_xKSjWvjJCU"
   },
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    train = pd.read_csv('data/train.csv')\n",
    "    test = pd.read_csv('data/test.csv')\n",
    "    labels = train['Response']\n",
    "    train.drop(labels='Response',axis = 1, inplace=True)\n",
    "    cols_to_drop = ['Id', 'Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32']\n",
    "  \n",
    "    train.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "    test.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "  \n",
    "    df = pd.concat([train,test])\n",
    "  \n",
    "    cat_cols = [\"Product_Info_1\", \"Product_Info_2\", \"Product_Info_3\", \"Product_Info_5\", \"Product_Info_6\", \n",
    "               \"Product_Info_7\", \"Employment_Info_2\", \"Employment_Info_3\", \"Employment_Info_5\", \"InsuredInfo_1\",\n",
    "               \"InsuredInfo_2\", \"InsuredInfo_3\", \"InsuredInfo_4\", \"InsuredInfo_5\", \"InsuredInfo_6\", \"InsuredInfo_7\", \n",
    "              \"Insurance_History_1\", \"Insurance_History_2\", \"Insurance_History_3\", \"Insurance_History_4\", \"Insurance_History_7\", \n",
    "              \"Insurance_History_8\", \"Insurance_History_9\", \"Family_Hist_1\", \"Medical_History_2\", \"Medical_History_3\", \"Medical_History_4\", \n",
    "              \"Medical_History_5\", \"Medical_History_6\", \"Medical_History_7\", \"Medical_History_8\", \"Medical_History_9\",\n",
    "              \"Medical_History_11\", \"Medical_History_12\", \"Medical_History_13\", \"Medical_History_14\", \"Medical_History_16\", \"Medical_History_17\",\n",
    "              \"Medical_History_18\", \"Medical_History_19\", \"Medical_History_20\", \"Medical_History_21\", \"Medical_History_22\", \"Medical_History_23\",\n",
    "              \"Medical_History_25\", \"Medical_History_26\", \"Medical_History_27\", \"Medical_History_28\", \"Medical_History_29\", \"Medical_History_30\", \n",
    "              \"Medical_History_31\", \"Medical_History_33\", \"Medical_History_34\", \"Medical_History_35\", \"Medical_History_36\", \n",
    "               \"Medical_History_37\", \"Medical_History_38\", \"Medical_History_39\", \"Medical_History_40\", \"Medical_History_41\"]\n",
    "  \n",
    "  \n",
    "    num_cols = ['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6',\n",
    "              'Insurance_History_5', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5','Medical_History_1']\n",
    "\n",
    "  # fill Nan values with mode for categorical variables, median for continuous variables\n",
    "    df = df.apply(lambda col: col.fillna(value = col.mode()[0] ) if col.name in cat_cols else col.fillna(value = col.median() ))\n",
    "  \n",
    "  # one-hot encoding categorical variables \n",
    "    dummies = pd.get_dummies(df, columns= cat_cols)\n",
    "  \n",
    "  # split data to train and test\n",
    "    train = dummies[:train.shape[0]]\n",
    "    test = dummies[train.shape[0]:]\n",
    "  \n",
    "  # scaling \n",
    "    scaler = StandardScaler_df()\n",
    "    train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "    test[num_cols] = scaler.transform(test[num_cols])\n",
    "  \n",
    "    return labels, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9hELGBcjaG4"
   },
   "outputs": [],
   "source": [
    "labels, train, test = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LsiO1Fa8jdmj",
    "outputId": "9f7578cc-3a41-476f-fd87-73305a9a634e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381,)\n",
      "(59381, 948)\n",
      "(19765, 948)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsSV03b3yQEh"
   },
   "source": [
    "## 3. Models Building and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntYbFbKkyQEi"
   },
   "source": [
    "*   <font color='red'>**Logistic Regression**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "SnmaRMEMyQEj",
    "outputId": "5dfc5302-4bc5-40f4-bccf-4d680977cad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression model\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQoPBUvxyQEx"
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "test_preds = model_lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdU9V_SzyQE1"
   },
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission[\"Response\"] = test_preds\n",
    "submission.to_csv('data/lr_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2hg7QymyQE4"
   },
   "source": [
    "**The logistic regression model scored 0.48729 on kaggle.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWVHgl2u1EaJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLdDoazhyQE5"
   },
   "source": [
    "* <font color='red'>**XGBoost** </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Di1pwc0wefpM"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lUYC0tAgMxj"
   },
   "outputs": [],
   "source": [
    "labels, train, test = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaH7ia6ff7Li"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train.values, labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mILd7cVteftX"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:linear',\n",
    "    'eval_metric':\"mae\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlZFaw0SfcBp"
   },
   "outputs": [],
   "source": [
    "num_boost_round = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkIRw6kbjLHU"
   },
   "outputs": [],
   "source": [
    "#Parameters max_depth and min_child_weight\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(5,7)\n",
    "    for min_child_weight in range(2,4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Pu_jO9IdjLMt",
    "outputId": "91697e7f-beda-4d4e-c2ce-5954407bc9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=5, min_child_weight=2\n",
      "\tMAE 1.4384842 for 49 rounds\n",
      "CV with max_depth=5, min_child_weight=3\n",
      "\tMAE 1.4378038 for 49 rounds\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tMAE 1.4332487999999999 for 49 rounds\n",
      "CV with max_depth=6, min_child_weight=3\n",
      "\tMAE 1.4343024 for 49 rounds\n",
      "Best params: 6, 2, MAE: 1.4332487999999999\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAGtcfom7Ltp"
   },
   "outputs": [],
   "source": [
    "# update params\n",
    "\n",
    "params['max_depth'] = 6\n",
    "params['min_child_weight'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhnzxyp9jLXO"
   },
   "outputs": [],
   "source": [
    "# Parameters subsample and colsample_bytree\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(4,6)]\n",
    "    for colsample in [i/10. for i in range(4,6)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "AXToGl-AjLcG",
    "outputId": "8fe3a48f-87a1-4093-ef7c-b6ddd3edae93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.5, colsample=0.5\n",
      "\tMAE 1.4447132000000003 for 44 rounds\n",
      "CV with subsample=0.5, colsample=0.4\n",
      "\tMAE 1.4478038 for 45 rounds\n",
      "CV with subsample=0.4, colsample=0.5\n",
      "\tMAE 1.448769 for 46 rounds\n",
      "CV with subsample=0.4, colsample=0.4\n",
      "\tMAE 1.4550662 for 49 rounds\n",
      "Best params: 0.5, 0.5, MAE: 1.4447132000000003\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYZRxGCWjLhs"
   },
   "outputs": [],
   "source": [
    "# update params\n",
    "\n",
    "params['subsample'] = 0.5\n",
    "params['colsample_bytree'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUJdkrcvjLtu"
   },
   "outputs": [],
   "source": [
    "# train xgb model\n",
    "train_xgb = xgb.DMatrix(train.values, labels.values)\n",
    "model_xgb = xgb.train(params, train_xgb,num_boost_round = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHB-p1dTfb-e"
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "test_xgb  = xgb.DMatrix(test.values)\n",
    "test_preds = model_xgb.predict(test_xgb,ntree_limit=model_xgb.best_iteration)\n",
    "test_preds = np.round(np.clip(test_preds,1,8)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QC3OsSv3fb8i"
   },
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission[\"Response\"] = test_preds\n",
    "submission.to_csv('data/xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JX0NoIsKxvX"
   },
   "source": [
    "**The XGBoost model scored 0.56787 on kaggle .** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj38OqbPONzF"
   },
   "source": [
    " Note: we can reach a better result if we use a more wide range for hyperparameters and many of them but that needs time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m58sj3y-yQFI"
   },
   "source": [
    "*  <font color='red'>**Neural Network**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOCtq6a-HAu_"
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, inputShape, layers, dropout = [], activation = 'relu', \n",
    "                 init = 'uniform', loss = 'rmse', optimizer = 'adadelta', nb_epochs = 50, batch_size = 32, verbose = 1):\n",
    "\n",
    "        model = Sequential()\n",
    "        for i in range(len(layers)):\n",
    "            if i == 0:\n",
    "                model.add(Dense(layers[i], input_dim = inputShape, init = init))\n",
    "            else:\n",
    "                model.add(Dense(layers[i], init = init))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(BatchNormalization())\n",
    "            if len(dropout) > i:\n",
    "                model.add(Dropout(dropout[i]))\n",
    "        model.add(Dense(1, init = init)) \n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        \n",
    "        self.model = model\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        self.model.fit(X.values, y.values, nb_epoch=self.nb_epochs, batch_size=self.batch_size, verbose = self.verbose)\n",
    "        \n",
    "    def predict(self, X, batch_size = 128, verbose = 1):\n",
    "        return self.model.predict(X.values, batch_size = batch_size, verbose = verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3723
    },
    "colab_type": "code",
    "id": "vSxqgRndCyJD",
    "outputId": "9dde97b9-3802-49e0-da23-0fdc3b87bbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: 948\n",
      "Adding Layer 0: 128\n",
      "Adding relu layer\n",
      "Adding 0.5 dropout\n",
      "Adding Layer 1: 64\n",
      "Adding relu layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, input_dim=948, kernel_initializer=\"glorot_normal\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_initializer=\"glorot_normal\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0.5 dropout\n",
      "Adding Layer 2: 32\n",
      "Adding relu layer\n",
      "Adding 0.7 dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, kernel_initializer=\"glorot_normal\")`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"glorot_normal\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59381/59381 [==============================] - 23s 393us/step - loss: 2.5981\n",
      "Epoch 2/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.8635\n",
      "Epoch 3/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.7423\n",
      "Epoch 4/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.6581\n",
      "Epoch 5/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.6049\n",
      "Epoch 6/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.5561\n",
      "Epoch 7/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.5283\n",
      "Epoch 8/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.5093\n",
      "Epoch 9/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4896\n",
      "Epoch 10/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4806\n",
      "Epoch 11/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4754\n",
      "Epoch 12/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4632\n",
      "Epoch 13/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4587\n",
      "Epoch 14/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4564\n",
      "Epoch 15/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4540\n",
      "Epoch 16/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4503\n",
      "Epoch 17/100\n",
      "59381/59381 [==============================] - 21s 357us/step - loss: 1.4444\n",
      "Epoch 18/100\n",
      "59381/59381 [==============================] - 21s 355us/step - loss: 1.4420\n",
      "Epoch 19/100\n",
      "59381/59381 [==============================] - 21s 355us/step - loss: 1.4401\n",
      "Epoch 20/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4411\n",
      "Epoch 21/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4390\n",
      "Epoch 22/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4376\n",
      "Epoch 23/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4338\n",
      "Epoch 24/100\n",
      "59381/59381 [==============================] - 21s 355us/step - loss: 1.4401\n",
      "Epoch 25/100\n",
      "59381/59381 [==============================] - 21s 355us/step - loss: 1.4364\n",
      "Epoch 26/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4336\n",
      "Epoch 27/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4324\n",
      "Epoch 28/100\n",
      "59381/59381 [==============================] - 21s 355us/step - loss: 1.4339\n",
      "Epoch 29/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4310\n",
      "Epoch 30/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4363\n",
      "Epoch 31/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4305\n",
      "Epoch 32/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4265\n",
      "Epoch 33/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4256\n",
      "Epoch 34/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4299\n",
      "Epoch 35/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4220\n",
      "Epoch 36/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4230\n",
      "Epoch 37/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4272\n",
      "Epoch 38/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4246\n",
      "Epoch 39/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4198\n",
      "Epoch 40/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4215\n",
      "Epoch 41/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4231\n",
      "Epoch 42/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4165\n",
      "Epoch 43/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4229\n",
      "Epoch 44/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4211\n",
      "Epoch 45/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4157\n",
      "Epoch 46/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4169\n",
      "Epoch 47/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4188\n",
      "Epoch 48/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4190\n",
      "Epoch 49/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4222\n",
      "Epoch 50/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4219\n",
      "Epoch 51/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4218\n",
      "Epoch 52/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4148\n",
      "Epoch 53/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4171\n",
      "Epoch 54/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4172\n",
      "Epoch 55/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4209\n",
      "Epoch 56/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4109\n",
      "Epoch 57/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4171\n",
      "Epoch 58/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4184\n",
      "Epoch 59/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4161\n",
      "Epoch 60/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4189\n",
      "Epoch 61/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4160\n",
      "Epoch 62/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4142\n",
      "Epoch 63/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4173\n",
      "Epoch 64/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4125\n",
      "Epoch 65/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4080\n",
      "Epoch 66/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4146\n",
      "Epoch 67/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4095\n",
      "Epoch 68/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4144\n",
      "Epoch 69/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4136\n",
      "Epoch 70/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4170\n",
      "Epoch 71/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4073\n",
      "Epoch 72/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4079\n",
      "Epoch 73/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4084\n",
      "Epoch 74/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4058\n",
      "Epoch 75/100\n",
      "59381/59381 [==============================] - 21s 347us/step - loss: 1.4053\n",
      "Epoch 76/100\n",
      "59381/59381 [==============================] - 21s 348us/step - loss: 1.4082\n",
      "Epoch 77/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4066\n",
      "Epoch 78/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4094\n",
      "Epoch 79/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4120\n",
      "Epoch 80/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4067\n",
      "Epoch 81/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4063\n",
      "Epoch 82/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4115\n",
      "Epoch 83/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4067\n",
      "Epoch 84/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4090\n",
      "Epoch 85/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4085\n",
      "Epoch 86/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4064\n",
      "Epoch 87/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4039\n",
      "Epoch 88/100\n",
      "59381/59381 [==============================] - 21s 354us/step - loss: 1.4040\n",
      "Epoch 89/100\n",
      "59381/59381 [==============================] - 21s 353us/step - loss: 1.4010\n",
      "Epoch 90/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4011\n",
      "Epoch 91/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4057\n",
      "Epoch 92/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4021\n",
      "Epoch 93/100\n",
      "59381/59381 [==============================] - 21s 349us/step - loss: 1.4045\n",
      "Epoch 94/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4075\n",
      "Epoch 95/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.3970\n",
      "Epoch 96/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4027\n",
      "Epoch 97/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.3958\n",
      "Epoch 98/100\n",
      "59381/59381 [==============================] - 21s 350us/step - loss: 1.4008\n",
      "Epoch 99/100\n",
      "59381/59381 [==============================] - 21s 351us/step - loss: 1.4040\n",
      "Epoch 100/100\n",
      "59381/59381 [==============================] - 21s 352us/step - loss: 1.4043\n"
     ]
    }
   ],
   "source": [
    "# train Nerual network model\n",
    "model_nn = NN(inputShape = train.shape[1], layers = [128, 64, 32], dropout = [0.5, 0.5, 0.7], loss='mae', optimizer = 'adadelta', init = 'glorot_normal', nb_epochs = 100)\n",
    "model_nn.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "suiHu_2wCyN6",
    "outputId": "c7e32a74-1eb5-4bda-be7c-401dc7be537d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19765/19765 [==============================] - 1s 26us/step\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "test_preds = model_nn.predict(test)\n",
    "test_preds = np.clip(np.round(test_preds), 1, 8).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfBB8fdwCyUO"
   },
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission[\"Response\"] = test_preds\n",
    "submission.to_csv('data/nn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bo3gCvzg4QDn"
   },
   "source": [
    "**The Deep neural network model scored 0.57065 on kaggle.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnltmEizeW0H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
